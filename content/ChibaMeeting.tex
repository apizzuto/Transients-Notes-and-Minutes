\chapter{Chiba Fall Collaboration Meeting: September 2019}

\section*{Realtime Parallel Sessions}
\begin{itemize}
    \item \textbf{Gravitational-wave Open Public Alerts and O3 Run News Including LLAMA-GWHEN Update (Zsuzsa Marka):} Zsuzsa summarizes the status of O3, sharing insight on what information is available in the Open Public Alerts (OPA). Stability increased from LIGO side due to 5 minute delay. Zsuzsa mentions some specific information, i.e. EMCOINC label with agreements for some collaborations. ``If it says BBH believe it.'' For NSBH, the neutron star \textit{may} be a BH. Commissioning break scheduled for October 1st to November 1st, O4 planned to start in 2022. Zsuzsa also outlines the status and improvements to LLAMA from O1 to O3. Subthreshold update in Gong talk. Justin asks about chances for individual mass estimates, Zsuzsa mentions that this may or may not happen, depending on LVC approval, not likely soon. 
    \item \textbf{Updates on Neutrino Follow Ups to Gravitational Wave Events (Raamis Hussain):} Raamis summarizes the status of his analysis. Quick recap of method and of the 40 GW events he has followed up to date, mentioning specifically the most significant event ($p= 0.0136$), the first NSBH, a GBM-LVC coincidence, and showing an overall p-value distribution. Raamis also shows his calculation of upper limits on the isotropic equivalent energy emitted in neutrinos, 
    $$ E_{\mathrm{iso}}=4 \pi r^{2} \int E \frac{d N}{d E d A d t} d E\;.$$ In terms of IceCube simulation, this samples from MC events, $$ \mu=\sum_{i}^{N} P\left(\Omega_{i}\right) \sum_{j}^{N_{\text {band }}} \frac{w_{i} E_{i}^{-2}}{\Delta \Omega_{\text {band }}} \frac{E_{\text {iso }}}{ 4 \pi \ln (E) |_{1}^2} I\;,$$ where $I$ encodes the distance PDF integral of the relevant pixel. The distribution of these $E_{iso}$ upper limits scales with the followed up events as $r^2$, and the limits are constrain the energy emitted in neutrinos to be less than 0.1 - 10\% of the energy released from the entire system (depending on the distance). See Justin's Gong talk for a stacked analysis and Raamis's Gong talk on searches for longer timescale emission. Lots of discussion on whether or not we should be trials correcting in all GCN circulars. 
    \item \textbf{Deep Neural Network Identification of Background Events in the HESE Realtime Stream (Theo Glauch):} Theo presents a method to increase the purity in the HESE realtims stream. First, verification of DNN showing Data / MC agreemend in HESE 7.5 years. When applied to archival data, cascades mainly agree with HESE, but some difference with other categories. Theo shows some HESE events that his DNN classifies as through-going tracks. Seems to still be missing some starting tracks (possibly issue because of SplineMPE). Theo suggests in the future that first a classification is made, and then a reconstruction is chosen based on the classification. Theo is able to keep 94\% of signal while eliminating all [available] MuonGun background.
    \item \textbf{Neutrino Alert Catch-up (Robert Stein):} Robert summarizes all of the alert events since Madison, giving an overview of millipede scans and followup efforts from other observatories, and granting them all wonderful names. For the 190730A event, Robert highlights the multiwavelength followups, drawing attention to the OVRO radio lightcurve. Robert also mentions the events which were not sent out because they happened before the v2 alert streams went live. Some questions about why the millipede contours are larger. Chad mentions that we might want to start using not those green circle errors in our point source analyses. 
    \item \textbf{Status and plans for realtime alert reports and neutrino database (Marcos Santander):} Marcos mentions two projects: (1) neutrino catalog and (2) realtime reports for the IceCube alerts. Marcos describes some details of the MongoDB based catalog and shows some features of the catalog. Marcos also shows some features of his realtime alert reports, which include skymaps, nearby Fermi sources (with links to Simbad, FAVA,  and ASDC Data Explorer), visibility for other observatories. He also discusses future plans for functionality and permanent hosting. 
    \item \textbf{A Background-only Clustering Likelihood for GFU/GRECO (Michael Larson):} Michael presents a new analysis idea for an untriggered flare analysis with the GRECO event stream. Goal is as signal agnostic as possible of an analysis. For energy term, don't assume a spectrum, just compare to expectations from atmospheric backgrounds. For timing, instead of assuming a time window, use the Erlang likelihood which describes timing between events $$ f(x ; k, \lambda)=\frac{\lambda^{k} x^{k-1} e^{-\lambda x}}{(k-1) !} \;.$$ This manifests as a timing likelihood as $$ \mathcal{L}_{i}=\log \left(M a x_{(k)}\left(1-\sum_{n=0}^{k-1} \frac{1}{n !} e^{-\lambda\left(t_{i}-t_{i-k}\right)}\left(\lambda\left(t_{i}-t_{i-k}\right)\right)^{n}\right)\right) \;.$$ Michael shows a toy MC assuming a certain rate with some signal and shows the ability to reconstruct this signal with a toy MC, as well as with scrambled GFU background. 
\end{itemize}

\section*{ROC Meeting}  
\cleanchapterquote{$1 \big/ r^2$ is a harsh mistress}{Erik Blaufuss}

\\

Spent a lot of time discussing what we should do about the contours with the alert events. Might look into using the $\Delta LLH$ value from the diffuse sample instead of IC160427A. Chad suggests just not publicizing the SplineMPE parabaloid errors in favor of something along the lines of ``events like this tend to be reconstructed with errors like XX.'' Some other items are the desire to quickly update the fast response analysis and get gravitational wave responses running more efficiently on the realtime nodes. Also discussion on a better realtime public footprint. This includes a better database for the alert events, Claudio mentioned that there is a request for funding for a newer GCN type platform development. Also discussed putting all of the gravitational wave responses and fast response analyses on one online portal, for example a \texttt{roc.icecube.wisc.edu}. Justin raised the point of needing to password protect current information that is not technically public. Also mentioned the FRA website progress. For next generation of alerts, Justin suggests cascades, especially important for short timescale transients (``they're better than LIGO contours''). Possible rolling out of OFU if short timescale GFU is performing well enough (Anna has a new Master's student that will be looking into this). Discussed ROC membership, Elisa asked about making the GFU reports more public at least to P.I.s of IceCube or \texttt{icecube-c}. Raamis showed a slide about what to do about per-event p-values for gravitational wave events. Idea of removing all but one event and repeating analysis for events of interest seems well received, but recommended it is presented to the Nu-sources audience.

\section*{Neutrino Sources Parallel One}
\begin{itemize}
    \item \textbf{GRB Precursor and Afterglow analysis update (Kunal Deoskar):} Kunal presents an update to his analysis searching for neutrinos outside of the prompt phase of GRBs. Signal search finds a $T_0$ and fits an extent of box time window. Analysis was using \texttt{psLab}, similar discovery potentials for different singal injection schemes. Moving analysis to csky. Plans to use a binomial test to analyze ensemble, using GRBs from GRBWeb in the Northern Sky, considering time windows of 1 s to 14 days. Only using well localized GRBs. Not much overlap between nearby in space and time GRBs. Shows BG TS distribution including binomial procedure and outlines next steps. 
    \item \textbf{GRB precursor stacking analysis (Paul Coppin):} Paul gives a recap of his precursor analysis, which searches for coincidence with lightcurves from the GBM using bayesian blocks algorithm for the lightcurve. On a per-GRB basis, sensitivity improved by a factor of about 2 compared to historic analysis, and when stacking by nearly an order of magnitude for hard spectra. For GBM bursts, procedure to include prior informatioin. Paul presents the status of GRBweb 2, which catalogs GRBs and is automatically updated, which h has developed to create a catalog of GRBs to followup. Questions from Ignacio about what years GBM skymaps will be avaiable for (potentially back to 2011). Michael asked if the healpix methodology is the same how it is done in Skylab (Lisa mentions that it might not be exactly the same, but she is in discussion with Mike Richman). Michael also asked about precursor and Liz's analysis overlap
    \item \textbf{GRB Coincidence Analysis Updates (Elizabeth Friedman):} Liz gives an update on her analysis, a potential realtime followup to GRBs, focusing specifically the large uncertainties from bursts detected by Fermi=GBM. Errors from the GBM are larger than were previously being treated. Computation time is a potential issue with large time windows and large uncertainties, so she also wants to use precomputed background trials (with a nice step-by-step pictorial representation of the analysis). For non-GRB bursts, Liz wants to use the same method as with GBM bursts, but just setting one pixel on the entire sky to 1 and the rest to 0. Shapes overall look good, potentially difference between single pixel healpix treatment and traditional method, but maybe statistical fluctuations. Nick asks why Liz does a fit around the GRB position if the GRB has a good localization, Liz just says it's just a fail safe to not miss reconstructed signal (if I followed her answer). 
    \item \textbf{Multiflare Updates/Unblinding Proposal (William Luszczak):} Will presents an update and unblinding request for his multiflare analysis. Begins with overview of method, showing how you can be throwing away signal with single flare fit, and defines his test statistic. To parameterize injecting flares, you can define an ensemble of flares with $$ N_{\text {flares}}=A_{m} \int_{I_{o}}^{\infty}\left(\frac{\alpha-1}{I_{o}}\right)\left(\frac{I}{I_{o}}\right)^{-\alpha} d I \;,$$ and this method has been used before in some model papers. It is just a distribution of number and intensity, not time of flares. Current unblinding proposal is for source catalog search, not all sky analysis yet (future work). Will shows the region of parameter space where his analysis is more sensitive to single flare fits and time-integrated searches. Will also goes over some reviewer questions, including the motivation for the flare intensity power law (he shows there is some motivation in gamma-ray sources). Source catalog is now all 3LAC blazars in the northern sky. Will also discusses source localization for using the IceCube events as a source list, and the [small but noticeable] worsening of the discovery potential associated with treating them as perfectly localized. Markus asks about the parameterization, and he says the 3 parameter fit also makes physical sense. A decent amount of questions from many people about patterns for different dimensions of the parameter space, including how tuned the parameters were on slide 11, and injected energy spectra of the sources.  
    \item \textbf{Search for Transients with GRECO update (Ignacio Taboada):} Ignacio presents the status of the transient analysis with GRECO implemented in cSky. Right now, beginning with time-integrated analysis with no energy term. Fits to background distributions seem to behaving as they should be, when looking at the parameters in the $\xi^2$ fit. Ignacio shows sensitivities in terms of number of signal events. Integrating over one year it is a huge number. Also plots showing the ability to spatially reconstruct signal. Goal is to move forward with an all-sky time-dependent analysis. 
    \item \textbf{Time Variability Test for Candidate Neutrino Sources (Taunton) (Ignacio Taboada):} Ignacio presents Pranav's analysis, which seeks to answer the question is data consistent with time variability? It is not a likelihood ratio analysis. First, select events in a region around a source, cut by $N$ with highest $S/B$, calculate $\Delta t$ for consecutive events, weight by $S/B$, weight $\Delta t$ by geometric mean of $\log(S/B)$, calculate CDF of this distribution. Figure of merit for the CDF uses Cramer-von Mises method, comparing the CDF of the data with non-variability expectation by $$A^{2}=N_{\mathrm{ev}} \int_{0}^{1}\left(F_{n}(x)-F(x)\right)^{2} d F(x) \; .$$ Ignacio shows some sample calculations with different injection schemes. Ignacio also shows a sample of TS distributions. Next are how significant certain temporal structures can acheive. Method does have the ability to test arbitrary time variability (including multiple flares). Pranav is requesting reviewers for the analysis. 
\end{itemize}

\section*{Neutrino Sources Parallel Two}
\begin{itemize}
    \item \textbf{Search for UHECR-neutrino correlation - analysis updates (Lisa Schumacher):} Lisa presents an update for her analysis, comparing the standard analysis (unblinded for ICRC) to a new analysis approach. New analysis motivated by the fact that not all UHECRs may have correlated neutrino sources. Alternative approach is to only add information from the strongest signal-like hotspots. Lisa shows the way one maps the local test statistics to an overall $p$-value. Lisa then shows the new sensitivity of this analysis. Sensitivities are fairly similar, Lisa is currently investigating if there is discovery space that gain be gained with this new method. One idea: try to recover the ``correlation fraction, $f$,'' which is the fraction of neutrino sources from UHECR sources. Also investigating neutrino hotspots fitted as counterparts to multiple UHECRs.
    \item \textbf{Ultra-Luminous Infrared Galaxies - Analysis Update (Pablo Correa):} Motivation from the Bechtol et al. Starburst Galaxy paper, arguing that a promising source of neutrinos is those which are opaque to gamma rays. Source class is ultra-luminous infrared galaxies, total of 189 sources selected from 3 catalogs. Weighting sources based off of luminosity distance. Pablo shows some distributions, with global $\gamma$ and $n_s$ fit. Pablo compares to 3FHL blazar stacking as well as to Tessa's 10 year analysis. Comparable sensitivity for similar number of sources for 3FHL stacking, and individual ULIRG contribution well below all-sky scan 10 year PS sensitivity. Markus asks about the highest star on the plot on slide 9, asking about that object. Ignacio points out that this is not truly the best way to visualize the sensitivity per source and offers a suggestion. Ali echoes Ignacio's point. 
    \item \textbf{Correlating blazars and neutrino alerts (Robert Stein):} Robert presents a new analysis correlating blazars and neutrino alerts. Motivation and context: we know some alert events are coincident with some blazars, is there a way to combine all of these coincidences to calculate a global p-value? Idea is to perform a stacking analysis, fixing the few millipede scans which we have and then scatter the blazars instead of the neutrinos. Robert demonstrates the method with a toy model. Background distribution well fit by Gamma distribution. Robert also describes the methodology for injecting signal, and gives a rough estimate of the number of neutrino associations for different fractions of the astrophysical flux coming from blazars. He also outlines the next steps for the analysis. 
    \item \textbf{Search for Novae with GRECO (Alex Pizzuto):}
    \item \textbf{Search for neutrino emission from binary sources (Qinrui Liu):} Hadronic models of binaries predict TeV gamma rays and neutrinos, models abound. Analysis specifics: time-dependent analysis using Bayesian Blocks based lightcurves. Source list includes 77 Galactic BH binaries from Watchdog, 67 of which have hard X-ray lightcurves up to 2017. Including the HEASARC catalog and Swift/BAT catalog increases this source list. For lightcurves, bayesian blocks applied to all SWIFT sources. Still deciding between WATCHDOG and SWIFT/BAT. Analysis is potentially moving to csky, Qinrui presents some cross hecks, specifically for Cyg X-1, between the two frameworks. 
    \item \textbf{Neutrinos from AGN cores (Federica Bradascio):} Federica presents a status update of her AGN core analysis. Both $p\gamma$ and $pp$ scenarios are plausible in these environments, X-ray emission is possible proxy for neutrino flux. Federica describes the specifics for the two subpopulations considered, radio-selected AGN and IR-selected AGN. For IR-selected AGN, assign a seyfertness to each source. In discovery potential calculation, Federica investigates a bias that manifests when injecting signal from a source class with high number density. Federica shows a $\log(N>S)$-$\log(S)$ plot and discusses bias in the source catalogs. Analysis shows sensitivity for hard spectra for radio-selected AGN, though no large dicovery parameter space. Future updates on other spectra and other samples.  
\end{itemize}

\section*{Neutrino Source Parallel Three}
\begin{itemize}
    \item \textbf{Update on Extended Source Analysis (Devyn Rysewyk):} Devyn presents an update to the extended source analysis, reminding that for large extended sources (as motivated by gamma-ray observatories), traditional PS likelihood does not perform well. 
    Will cautions that some of the differences might just be because the two versions of the event selection used for the plots are 2.0 and 3.0, which is a large difference between those datasets. 
    \item \textbf{Galaxy Clusters Analysis Update (Mehr Nisa):} Galaxy clusters potentially interesting because gas in intra-cluster media provide target material for cosmic-ray interactions. Idea is to extend previous analysis focused on 5 nearby clusters to a full population-specific study with 10 year point source dataset
    
    Theo asked about motivation for scaling by X-ray flux. Markus says X-ray isn't the only choice, but it's just a luminosity distance weighting scheme essentially.
    \item \textbf{ ():}
    \item \textbf{ ():}
    \item \textbf{ ():}
    \item \textbf{ ():}
\end{itemize}

\section*{Neutrino Source Gong}
\begin{itemize}
    \item \textbf{ESTES Point Source Teasers (Sarah Mancina):} ESTES point source analyses: all-sky seach, catalog, catalog stacking, galactic plane template, realtime alerts. Description of treatment of angular error, includes millipede length, as well as zenith, fitting a double Gaussian
    \item \textbf{Automatic Multi-Wavelength Follow-Up of Iceube Realtime Alerts (Theo Glauch):} Looking just at gamma-ray counterparts is not sufficient, can we generate fuller SEDs for sources in the IceCube alert contours? Start with radio and x-ray information, with counterpart candidates look into gamma rays, generate single source SEDs, manifests in full multi-wavelength lightcurves. Goal is make full multi-wavelength analysis automatic and publicly available through \textit{OpenUniverse} to optimize followups
    \item \textbf{A search for neutrinos from hard X-ray AGN (Marcos Santander):} Use hard x-rays as hadronic emission markers. Motivation: hadronically produced gammas cascade to hard x-ray to MeV range. Using Swift-BAT and BASS catalog. Some are beamed, many nearby. Outlines next steps
    \item \textbf{Impact of UHECR composition on UHECR-neutrino-correlation analysis (Lisa Schumacher):} Cosmic-ray proton fraction highly uncertain, and it affects correlation study because composition affects deflection. Smaller deflection for protons. Goal is to set limits that include the composition parameters. Also, correlation fraction does not seem to drastically affect the sensitivity of the analysis.
    \item \textbf{Subthreshold LLAMA-GWHEN Search (Zsuzsa Marka):} Code does not need to drastically change to run on subthreshold alerts. However, might want to weight analyses by SNR, not currently implemented. Purposed subthreshold offline O2 search as well as O3 online search. 
    \item \textbf{Extracting Angular Uncertainties for GRECO Online (Michael Larson):} New online GRECO dataset running at pole. Factor of 2-3 larger effective area than historic GRECO analysis. Using MultiNest to extract errors is efficient way to deal with bumpy likelihood space. Sharp boundaries from ellipse boundaries. Smoothen by Kent Mixed-Model parameterization. Still need to extract $\sigma$ values and pull correct. 
    \item \textbf{Time-dependent stacking of neutrino events at pre-public EHE alert positions (Jan Soedingrekso):} Often insignificant warm spots near EHE positions. Describes procedure to deal with overlapping time windows from nearby temporally events.
    \item \textbf{Proposal for Neutrino Search from Kilonovae (Raamis Hussain):} Current analyses only look at emission in short time windows. Potentially interesting to look out further (2 weeks). If a host galaxy is identified, run fast response analysis, otherwise, run the analysis with LIGO likelihood information. Consider any event with combined probability of P(BBH) + P(Mass Gap) less than 50\%. Like to run archivally and in realtime. 
    \item \textbf{TXS cross checks with new data samples (Will Luszczak):} New datasamples exist (GFU, new PSTracks, new Northern Tracks). Would like to rerun TXS analyses, restricting samples to same time period as old samples as a check. Will shows the whole analysis code
    \item \textbf{A Multimap Method (Rob Halliday):} Goal is to combine different datasets to identify coincidences between different bands. Toy example results shown. 
    \item \textbf{Neutrino Sources Dataset Updates & Reminders (Liz Friedman):} Overview of current status of datasets and guidelines for the working group. 
    \item \textbf{Archival Search for Coincident Time-translated Transient Events between IceCube and HAWC (Alison Peisker):} Many models for delayed neutrino and gamma-ray emission. Need long term searches to find these excesses. Look for excesses in HAWC data triggering on IceCube alert events.
    \item \textbf{Constraining Neutrino Emission from the > 100 TeV HAWC Sources (Mehr Un Nisa):} Idea is to use updated list of high energy HAWC sources, including spatial extent, to extend previous IceCube-HAWC analyses. Don't assume exponential cutoff at 300 TeV.
    \item \textbf{Stacking gravitational wave analysis (Justin Vandenbroucke):} Entering the realm of population studies with gravitational wave progenitors. Unique because GWs come with distance measurements. Sensitivity scales incersely with the number of sources. Proposed distance weighted analysis, sensitivity should be at least a f
\end{itemize}

Right now, analysis looks at separate distributions, but I imagine for subthreshold events that it's more difficult to reconstruct merger event characteristics. Is this a big deal and if so will it be folded into the way you compare to background distributions